{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bbc4a980",
      "metadata": {
        "id": "bbc4a980"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "import tensorflow_datasets as tfds\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import platform"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "34744ff9",
      "metadata": {
        "id": "34744ff9"
      },
      "source": [
        "## **Version Check**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c981e3e4",
      "metadata": {
        "id": "c981e3e4"
      },
      "outputs": [],
      "source": [
        "print(\"Tensorflow-gpu: \", tf.__version__)\n",
        "print(\"Tensorflow_datasets: \", tfds.__version__)\n",
        "print(\"Numpy: \", np.__version__)\n",
        "print(\"Matplotlib: \", matplotlib.__version__)\n",
        "print(\"Python: \", platform.python_version())"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3a4bb1a2",
      "metadata": {
        "id": "3a4bb1a2"
      },
      "source": [
        "## **IIIT PET3 dataset load**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cca073c6",
      "metadata": {
        "id": "cca073c6"
      },
      "outputs": [],
      "source": [
        "dataset, info = tfds.load('oxford_iiit_pet:3.*.*', with_info=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6ead59f2",
      "metadata": {
        "id": "6ead59f2"
      },
      "outputs": [],
      "source": [
        "# train set : 3680, test set : 3669\n",
        "print(info)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a8756f2e",
      "metadata": {
        "id": "a8756f2e"
      },
      "outputs": [],
      "source": [
        "print(dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0e778356",
      "metadata": {
        "id": "0e778356"
      },
      "outputs": [],
      "source": [
        "print(dataset[\"train\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "087ce40b",
      "metadata": {
        "id": "087ce40b"
      },
      "source": [
        "## **Data Preprocessing**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bc6dd1cc",
      "metadata": {
        "id": "bc6dd1cc"
      },
      "outputs": [],
      "source": [
        "def resize(input_image, input_mask):\n",
        "    input_image = tf.image.resize(input_image, (128, 128), method=\"nearest\")\n",
        "    input_mask = tf.image.resize(input_mask, (128, 128), method=\"nearest\")\n",
        "\n",
        "    return input_image, input_mask \n",
        "\n",
        "def augment(input_image, input_mask):\n",
        "    if tf.random.uniform(()) > 0.5:\n",
        "        # Random flipping of the image and mask\n",
        "        input_image = tf.image.flip_left_right(input_image)\n",
        "        input_mask = tf.image.flip_left_right(input_mask)\n",
        "\n",
        "    return input_image, input_mask\n",
        "\n",
        "def normalize(input_image, input_mask):\n",
        "    input_image = tf.cast(input_image, tf.float32) / 255.0\n",
        "    input_mask -= 1\n",
        "  \n",
        "    return input_image, input_mask\n",
        "\n",
        "def load_image_train(datapoint):\n",
        "    input_image = datapoint[\"image\"]\n",
        "    input_mask = datapoint[\"segmentation_mask\"]\n",
        "    input_image, input_mask = resize(input_image, input_mask)\n",
        "    input_image, input_mask = augment(input_image, input_mask)\n",
        "    input_image, input_mask = normalize(input_image, input_mask)\n",
        "\n",
        "    return input_image, input_mask\n",
        "\n",
        "def load_image_test(datapoint):\n",
        "    input_image = datapoint[\"image\"]\n",
        "    input_mask = datapoint[\"segmentation_mask\"]\n",
        "    input_image, input_mask = resize(input_image, input_mask)\n",
        "    input_image, input_mask = normalize(input_image, input_mask)\n",
        "\n",
        "    return input_image, input_mask"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c918eb08",
      "metadata": {
        "id": "c918eb08"
      },
      "outputs": [],
      "source": [
        "train_dataset = dataset[\"train\"].map(load_image_train, num_parallel_calls=tf.data.AUTOTUNE)\n",
        "test_dataset = dataset[\"test\"].map(load_image_test, num_parallel_calls=tf.data.AUTOTUNE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5826ed7b",
      "metadata": {
        "id": "5826ed7b"
      },
      "outputs": [],
      "source": [
        "print(train_dataset)\n",
        "print(len(train_dataset)) # 3680\n",
        "print(len(test_dataset))  # 3669"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0548c951",
      "metadata": {
        "id": "0548c951"
      },
      "source": [
        "## **Divide to Training/Validation/Test set**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9834f4a5",
      "metadata": {
        "id": "9834f4a5"
      },
      "outputs": [],
      "source": [
        "BATCH_SIZE = 16\n",
        "BUFFER_SIZE = 1000\n",
        "\n",
        "train_batches = train_dataset.cache().shuffle(BUFFER_SIZE).batch(BATCH_SIZE).repeat()\n",
        "train_batches = train_batches.prefetch(buffer_size=tf.data.experimental.AUTOTUNE)\n",
        "validation_batches = test_dataset.take(3000).batch(BATCH_SIZE) \n",
        "test_batches = test_dataset.skip(3000).take(669).batch(BATCH_SIZE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5799b4db",
      "metadata": {
        "id": "5799b4db"
      },
      "outputs": [],
      "source": [
        "print(train_batches)       # 3680\n",
        "print(validation_batches)  # 3000\n",
        "print(test_batches)        # 669"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e9f5b2e9",
      "metadata": {
        "id": "e9f5b2e9"
      },
      "outputs": [],
      "source": [
        "def display(display_list):\n",
        "    plt.figure(figsize=(15, 15))\n",
        "\n",
        "    title = [\"Input Image\", \"True Mask\", \"Predicted Mask\"]\n",
        "\n",
        "    for i in range(len(display_list)):\n",
        "        plt.subplot(1, len(display_list), i+1)\n",
        "        plt.title(title[i])\n",
        "        plt.imshow(tf.keras.utils.array_to_img(display_list[i]))\n",
        "        plt.axis(\"off\")\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c291da1b",
      "metadata": {
        "id": "c291da1b"
      },
      "outputs": [],
      "source": [
        "sample_batch = next(iter(test_batches))\n",
        "random_index = np.random.choice(sample_batch[0].shape[0])\n",
        "sample_image, sample_mask = sample_batch[0][random_index], sample_batch[1][random_index]\n",
        "display([sample_image, sample_mask])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "da6835fd",
      "metadata": {
        "id": "da6835fd"
      },
      "source": [
        "![un](https://drive.google.com/file/d/17PGt30bECo7OaLLg6ESklmGw_NyE6Dt9/view?usp=sharing)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "92edcad6",
      "metadata": {
        "id": "92edcad6"
      },
      "outputs": [],
      "source": [
        "def double_conv_block(x, n_filters):\n",
        "    # Conv2D then ReLU activation\n",
        "    x = layers.Conv2D(n_filters, 3, padding = \"same\", activation = \"relu\", kernel_initializer = \"he_normal\")(x)\n",
        "    # Conv2D then ReLU activation\n",
        "    x = layers.Conv2D(n_filters, 3, padding = \"same\", activation = \"relu\", kernel_initializer = \"he_normal\")(x)\n",
        "\n",
        "    return x\n",
        "\n",
        "def downsample_block(x, n_filters):\n",
        "    f = double_conv_block(x, n_filters)\n",
        "    p = layers.MaxPool2D(2)(f)\n",
        "    p = layers.Dropout(0.3)(p)\n",
        "\n",
        "    return f, p\n",
        "\n",
        "def upsample_block(x, conv_features, n_filters):\n",
        "    # upsample\n",
        "    x = layers.Conv2DTranspose(n_filters, 3, 2, padding=\"same\")(x)\n",
        "    # concatenate \n",
        "    x = layers.concatenate([x, conv_features])\n",
        "    # dropout\n",
        "    x = layers.Dropout(0.3)(x)\n",
        "    # Conv2D twice with ReLU activation\n",
        "    x = double_conv_block(x, n_filters)\n",
        "\n",
        "    return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e4db111c",
      "metadata": {
        "id": "e4db111c"
      },
      "outputs": [],
      "source": [
        "def build_unet_model():\n",
        "\n",
        "    # inputs\n",
        "    inputs = layers.Input(shape=(128,128,3))\n",
        "\n",
        "    # encoder: contracting path - downsample\n",
        "    # 1 - downsample\n",
        "    f1, p1 = downsample_block(inputs, 64)\n",
        "    # 2 - downsample\n",
        "    f2, p2 = downsample_block(p1, 128)\n",
        "    # 3 - downsample\n",
        "    f3, p3 = downsample_block(p2, 256)\n",
        "    # 4 - downsample\n",
        "    f4, p4 = downsample_block(p3, 512)\n",
        "\n",
        "    # 5 - bottleneck\n",
        "    bottleneck = double_conv_block(p4, 1024)\n",
        "\n",
        "    # decoder: expanding path - upsample\n",
        "    # 6 - upsample\n",
        "    u6 = upsample_block(bottleneck, f4, 512)\n",
        "    # 7 - upsample\n",
        "    u7 = upsample_block(u6, f3, 256)\n",
        "    # 8 - upsample\n",
        "    u8 = upsample_block(u7, f2, 128)\n",
        "    # 9 - upsample\n",
        "    u9 = upsample_block(u8, f1, 64)\n",
        "\n",
        "    # outputs\n",
        "    outputs = layers.Conv2D(3, 1, padding=\"same\", activation = \"softmax\")(u9)\n",
        "\n",
        "    # unet model with Keras Functional API\n",
        "    unet_model = tf.keras.Model(inputs, outputs, name=\"U-Net\")\n",
        "\n",
        "    return unet_model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "24a0cdda",
      "metadata": {
        "id": "24a0cdda"
      },
      "outputs": [],
      "source": [
        "unet_model = build_unet_model()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b6cf14aa",
      "metadata": {
        "id": "b6cf14aa"
      },
      "outputs": [],
      "source": [
        "unet_model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e1370b0b",
      "metadata": {
        "scrolled": false,
        "id": "e1370b0b"
      },
      "outputs": [],
      "source": [
        "tf.keras.utils.plot_model(unet_model, show_shapes=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a4888ae7",
      "metadata": {
        "id": "a4888ae7"
      },
      "outputs": [],
      "source": [
        "unet_model.compile(optimizer=tf.keras.optimizers.Adam(), loss=\"sparse_categorical_crossentropy\", metrics=\"accuracy\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b0e99cb0",
      "metadata": {
        "id": "b0e99cb0"
      },
      "outputs": [],
      "source": [
        "NUM_EPOCHS = 20\n",
        "\n",
        "TRAIN_LENGTH = info.splits[\"train\"].num_examples\n",
        "STEPS_PER_EPOCH = TRAIN_LENGTH // BATCH_SIZE\n",
        "\n",
        "VAL_SUBSPLITS = 5\n",
        "TEST_LENTH = info.splits[\"test\"].num_examples\n",
        "VALIDATION_STEPS = TEST_LENTH // BATCH_SIZE // VAL_SUBSPLITS\n",
        "\n",
        "model_history = unet_model.fit(train_batches,\n",
        "                               epochs=NUM_EPOCHS,\n",
        "                               steps_per_epoch=STEPS_PER_EPOCH,\n",
        "                               validation_steps=VALIDATION_STEPS,\n",
        "                               validation_data=validation_batches)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3451715b",
      "metadata": {
        "id": "3451715b"
      },
      "outputs": [],
      "source": [
        "def display_learning_curves(history):\n",
        "    acc = history.history[\"accuracy\"]\n",
        "    val_acc = history.history[\"val_accuracy\"]\n",
        "\n",
        "    loss = history.history[\"loss\"]\n",
        "    val_loss = history.history[\"val_loss\"]\n",
        "\n",
        "    epochs_range = range(NUM_EPOCHS)\n",
        "\n",
        "    fig = plt.figure(figsize=(12,6))\n",
        "\n",
        "    plt.subplot(1,2,1)\n",
        "    plt.plot(epochs_range, acc, label=\"train accuracy\")\n",
        "    plt.plot(epochs_range, val_acc, label=\"validataion accuracy\")\n",
        "    plt.title(\"Accuracy\")\n",
        "    plt.xlabel(\"Epoch\")\n",
        "    plt.ylabel(\"Accuracy\")\n",
        "    plt.legend(loc=\"lower right\")\n",
        "\n",
        "    plt.subplot(1,2,2)\n",
        "    plt.plot(epochs_range, loss, label=\"train loss\")\n",
        "    plt.plot(epochs_range, val_loss, label=\"validataion loss\")\n",
        "    plt.title(\"Loss\")\n",
        "    plt.xlabel(\"Epoch\")\n",
        "    plt.ylabel(\"Loss\")\n",
        "    plt.legend(loc=\"upper right\")\n",
        "\n",
        "    fig.tight_layout()\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5931aca1",
      "metadata": {
        "id": "5931aca1"
      },
      "outputs": [],
      "source": [
        "# Display learning curves \n",
        "display_learning_curves(unet_model.history)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b9c535a9",
      "metadata": {
        "id": "b9c535a9"
      },
      "outputs": [],
      "source": [
        "def create_mask(pred_mask):\n",
        "    pred_mask = tf.argmax(pred_mask, axis=-1)\n",
        "    pred_mask = pred_mask[..., tf.newaxis]\n",
        "    return pred_mask[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "65c35d5a",
      "metadata": {
        "id": "65c35d5a"
      },
      "outputs": [],
      "source": [
        "def show_predictions(dataset=None, num=1):\n",
        "    if dataset:\n",
        "        for image, mask in dataset.take(num):\n",
        "            pred_mask = unet_model.predict(image)\n",
        "            display([image[0], mask[0], create_mask(pred_mask)])\n",
        "    else:\n",
        "        display([sample_image, sample_mask, create_mask(model.predict(sample_image[tf.newaxis, ...]))])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "37bb4b6c",
      "metadata": {
        "id": "37bb4b6c"
      },
      "outputs": [],
      "source": [
        "count = 0\n",
        "for i in test_batches:\n",
        "    count +=1\n",
        "print(\"number of batches:\", count)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ebc85eb4",
      "metadata": {
        "id": "ebc85eb4"
      },
      "outputs": [],
      "source": [
        "show_predictions(test_batches.skip(5), 3)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.13"
    },
    "colab": {
      "name": "image segmentation example using Unet.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}